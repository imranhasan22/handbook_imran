{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4385ea0-a993-484b-b00f-f3e48f89be2d",
   "metadata": {},
   "source": [
    "# NLP\n",
    "A field of AI that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret and generate human languages in a way that is both meaningful and useful.\n",
    "\n",
    "## Applications of NLP\n",
    "- Search Engines\n",
    "- Chatbot\n",
    "- Language Translation\n",
    "- Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ef9fa-c982-440d-b9d9-5e3ab80a20b8",
   "metadata": {},
   "source": [
    "# Regular Expressions\n",
    "- `.` - matches any charecter except a newline\n",
    "- `\\w` - matches any word charecter(alphanumaric-equivalent to `[a-zA-Z0-9_]`)\n",
    "- `\\d` - matches any digit(`[0-9])\n",
    "- `\\s` - matches any whitespace character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2671a-b54c-4b4c-8c90-f05a1cf13065",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bb705-a067-4d48-8147-9d9c46ee9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca622faa-93f0-4b80-8113-c6dfbc6c7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4f41a-2d86-4976-bf3a-eefab87282fc",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "It involves splitting text into smaller units, known as tokens. This token can be phrases, sentences or other meaningful units, depending on the granularity of the tokenization.\n",
    "## Types\n",
    "- Word Tokenization\n",
    "- Sentence Tokenization\n",
    "- Subword Tokenization\n",
    "- Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b509cb-ea28-4685-a414-9243a11bd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "sentence=\"The quick brown fox jumps over the lazy dog. It was a sunny day\"\n",
    "\n",
    "words=word_tokenize(sentence)\n",
    "sentences=sent_tokenize(sentence)\n",
    "print(\"Word Tokens: \",end=\"\")\n",
    "print(words)\n",
    "print(\"Sentence Tokens: \",end=\"\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf831af1-37dc-4eaf-a1f3-280cfd287fd1",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "A text normalization technique used to reduce words to their base/root form. It simplify text data by reducing derived words to a common base form so that they can be analyzed as a single item.\n",
    "\n",
    "Stemming algorithms typically remove common word suffixes(int, ly, ed) to transform a word into its root form.\n",
    "\n",
    "__Example:__ `running` -> `run`, `better` -> `bet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28487e-c9e0-4854-bde8-2a7ed2caef02",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439f44f-1758-4581-866f-d9aa03b95a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3899a-3653-4824-9701-0b03faee0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word} -> {porter.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4423102-d538-4144-8d9c-c379a3c0c421",
   "metadata": {},
   "source": [
    "## SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9576bf-997d-4f59-a2aa-2684cadf4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball=SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(f\"{word}->{snowball.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43410db-306f-462a-9c23-d578bb94fa4f",
   "metadata": {},
   "source": [
    "## LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9c2d7-6dea-4d1d-be47-60ff5b9b0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster=LancasterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word}->{lancaster.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e68160-7516-4942-a046-ecb32798afa0",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "A text normalization technique used to reduce words to their base form but unlike stemming, it considers the context and morphological analysis of words, aiming to reduce words to their meaningful root forms.\n",
    "\n",
    "__Example:__ `running` -> `run`, `better` -> `good`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581f508-f37b-4df8-801d-820c43938960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322a017-5bb9-4650-8a4b-443db616be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eae4e2-4b69-410e-8e05-cfa09949a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    pos = get_wordnet_pos(word)\n",
    "    lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
    "    print(f\"{word}->{lancaster.stem(lemmatized_word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa020a0-d4a7-40d7-baeb-6e9b7bc2a0a7",
   "metadata": {},
   "source": [
    "# Parts Of Speech Tagging\n",
    "It involves assigning parts of speech to each word in a sentence or text.\n",
    "## Tags\n",
    "- `NN` - Noun\n",
    "- `VB` - Verb\n",
    "- `JJ` - Adjective\n",
    "- `RB` - Adverb\n",
    "- `PRP` - Pronoun\n",
    "- `IN` - Preposition\n",
    "- `CC` - Conjunction\n",
    "- `DT` - Determiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb452ab-35dc-4346-9021-94e06de3948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "for word in words:\n",
    "    print(f\"{word} -> {pos_tag([word])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490bada8-de3e-4270-be91-d1100072c8b0",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "It involves identifying and `classifying` named entities in text into `predefined categories` such as persons, organizations, locations, dates and more.\n",
    "## Categories of Named Entities\n",
    "- `PER` - Person\n",
    "- `ORG` - Oragnization\n",
    "- `LOC` - Location\n",
    "- `DATE/TIME` - Date/Time\n",
    "- `MONEY` - Monetary Values\n",
    "- `PERCENT` - Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786b0f6-830f-40b3-aeb8-85c863aa07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6fa613d-ee57-4b5c-a7c3-a0173f9c4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "792b8622-7dbf-4046-8494-a5dcd3cc6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4576dcef-f9e8-4bc2-8c9f-e7d06c7c9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n",
      "Barack Obama PERSON\n",
      "August 4, 1961 DATE\n",
      "Honolulu GPE\n",
      "Hawaii GPE\n"
     ]
    }
   ],
   "source": [
    "# doc=nlp(sentence)\n",
    "doc=nlp(\"Apple is looking at buying U.K. startup for $1 billion. Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc63d1a-29a4-48b3-9e47-4626b8bca48a",
   "metadata": {},
   "source": [
    "# Text Representation\n",
    "It convert textual data into a format that ml alogorithms can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de7f479e-b7f4-4a49-8770-19ec9c6ab20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\n",
    "    \"Natural Language Processing is fascinating.\",\n",
    "    \"Text represntation is crucial in NLP.\",\n",
    "    \"Word embeddings are a powerful tool in NLP\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcea968-f0d5-4d87-99b3-1f1f83076de5",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "It represent text as a collection of words without considering the order. It counts the frequency of each word in a document. The result is a vector where each dimension corresponds to a unique word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68c1bab-873b-465d-8ca6-047d9eb00893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37a30762-bbaf-4c4e-b4f2-a46793e6d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "bow_matrix=vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80502e1c-8fd6-4f9e-811f-be3a7edb4311",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "It refers to the set of all unique words found across the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d54d29da-3b9f-46e8-b61c-701286ef8f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are' 'crucial' 'embeddings' 'fascinating' 'in' 'is' 'language' 'natural'\n",
      " 'nlp' 'powerful' 'processing' 'represntation' 'text' 'tool' 'word']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd509403-4ee8-449e-9624-8a82a677c0bd",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "The vector has the same length as the number of unique words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6cf1d6-048e-4414-8a40-88ba788bba4c",
   "metadata": {},
   "source": [
    "__First Sentence:__ Natural Language Processing is fascinating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a1ccc-8213-4543-8d81-58dec3d95fcd",
   "metadata": {},
   "source": [
    "- `are`         - not present - 0\n",
    "- `crucial`     - not present - 0\n",
    "- `embeddings`  - not present - 0\n",
    "- `fascinating` - present     - 1\n",
    "- `in`          - not prsent  - 0\n",
    "- `is`          - not present - 0\n",
    "- `language`    - present     - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb6c4f09-c9d7-4e32-b97f-b86312a2f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 1 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 1 1 0 0 1 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 0 0 0 1 1 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482134d-cb5e-48d8-9c94-f64555a8a605",
   "metadata": {},
   "source": [
    "Each word in the sentence appear __one__ time which is why the array appear only 0 and 1, if any word appear multiple time, the number will be shown in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a99b3b0f-9210-474a-8cc1-725a030e1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 13)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498863e1-9674-4d49-9bd9-efa4414ac78d",
   "metadata": {},
   "source": [
    "#### `(0, 7)\t1`\n",
    "- `0` refers to the sentence\n",
    "- `7` refers to the word at index 7 in vocabulary\n",
    "- `1` refers it appears __1__ time in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a546e-be7b-4b45-8be9-abff08153591",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "It convert categorical data into numerical data assigning a unique integer value to each category.\n",
    "\n",
    "It "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
