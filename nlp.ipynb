{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4385ea0-a993-484b-b00f-f3e48f89be2d",
   "metadata": {},
   "source": [
    "# NLP\n",
    "A field of AI that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret and generate human languages in a way that is both meaningful and useful.\n",
    "\n",
    "## Applications of NLP\n",
    "- Search Engines\n",
    "- Chatbot\n",
    "- Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ef9fa-c982-440d-b9d9-5e3ab80a20b8",
   "metadata": {},
   "source": [
    "# Regular Expressions\n",
    "- `.` - matches any charecter except a newline\n",
    "- `\\w` - matches any word charecter(alphanumaric-equivalent to `[a-zA-Z0-9_]`)\n",
    "- `\\d` - matches any digit(`[0-9])\n",
    "- `\\s` - matches any whitespace character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2671a-b54c-4b4c-8c90-f05a1cf13065",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b38bb705-a067-4d48-8147-9d9c46ee9b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: click in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in t:\\project\\programming_notes\\python\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca622faa-93f0-4b80-8113-c6dfbc6c7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4f41a-2d86-4976-bf3a-eefab87282fc",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "It involves splitting text into smaller units, known as tokens. This token can be phrases, sentences or other meaningful units, depending on the granularity of the tokenization.\n",
    "## Types\n",
    "- Word Tokenization\n",
    "- Sentence Tokenization\n",
    "- Subword Tokenization\n",
    "- Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61b509cb-ea28-4685-a414-9243a11bd829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', 'It', 'was', 'a', 'sunny', 'day']\n",
      "Sentence Tokens: ['The quick brown fox jumps over the lazy dog.', 'It was a sunny day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "sentence=\"The quick brown fox jumps over the lazy dog. It was a sunny day\"\n",
    "\n",
    "words=word_tokenize(sentence)\n",
    "sentences=sent_tokenize(sentence)\n",
    "print(\"Word Tokens: \",end=\"\")\n",
    "print(words)\n",
    "print(\"Sentence Tokens: \",end=\"\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf831af1-37dc-4eaf-a1f3-280cfd287fd1",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "A text normalization technique used to reduce words to their base/root form. It simplify text data by reducing derived words to a common base form so that they can be analyzed as a single item.\n",
    "\n",
    "Stemming algorithms typically remove common word suffixes(int, ly, ed) to transform a word into its root form.\n",
    "\n",
    "__Example:__ `running` -> `run`, `better` -> `bet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28487e-c9e0-4854-bde8-2a7ed2caef02",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1439f44f-1758-4581-866f-d9aa03b95a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01b3899a-3653-4824-9701-0b03faee0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -> the\n",
      "quick -> quick\n",
      "brown -> brown\n",
      "fox -> fox\n",
      "jumps -> jump\n",
      "over -> over\n",
      "the -> the\n",
      "lazy -> lazi\n",
      "dog -> dog\n",
      ". -> .\n",
      "It -> it\n",
      "was -> wa\n",
      "a -> a\n",
      "sunny -> sunni\n",
      "day -> day\n"
     ]
    }
   ],
   "source": [
    "porter=PorterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word} -> {porter.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4423102-d538-4144-8d9c-c379a3c0c421",
   "metadata": {},
   "source": [
    "## SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b9576bf-997d-4f59-a2aa-2684cadf4e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The->the\n",
      "quick->quick\n",
      "brown->brown\n",
      "fox->fox\n",
      "jumps->jump\n",
      "over->over\n",
      "the->the\n",
      "lazy->lazi\n",
      "dog->dog\n",
      ".->.\n",
      "It->it\n",
      "was->was\n",
      "a->a\n",
      "sunny->sunni\n",
      "day->day\n"
     ]
    }
   ],
   "source": [
    "snowball=SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(f\"{word}->{snowball.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43410db-306f-462a-9c23-d578bb94fa4f",
   "metadata": {},
   "source": [
    "## LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cda9c2d7-6dea-4d1d-be47-60ff5b9b0a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The->the\n",
      "quick->quick\n",
      "brown->brown\n",
      "fox->fox\n",
      "jumps->jump\n",
      "over->ov\n",
      "the->the\n",
      "lazy->lazy\n",
      "dog->dog\n",
      ".->.\n",
      "It->it\n",
      "was->was\n",
      "a->a\n",
      "sunny->sunny\n",
      "day->day\n"
     ]
    }
   ],
   "source": [
    "lancaster=LancasterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word}->{lancaster.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e68160-7516-4942-a046-ecb32798afa0",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "A text normalization technique used to reduce words to their base form but unlike stemming, it considers the context and morphological analysis of words, aiming to reduce words to their meaningful root forms.\n",
    "\n",
    "__Example:__ `running` -> `run`, `better` -> `good`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8581f508-f37b-4df8-801d-820c43938960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7322a017-5bb9-4650-8a4b-443db616be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71eae4e2-4b69-410e-8e05-cfa09949a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The->the\n",
      "quick->quick\n",
      "brown->brown\n",
      "fox->fox\n",
      "jumps->jump\n",
      "over->ov\n",
      "the->the\n",
      "lazy->lazy\n",
      "dog->dog\n",
      ".->.\n",
      "It->it\n",
      "was->be\n",
      "a->a\n",
      "sunny->sunny\n",
      "day->day\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    pos = get_wordnet_pos(word)\n",
    "    lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
    "    print(f\"{word}->{lancaster.stem(lemmatized_word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa020a0-d4a7-40d7-baeb-6e9b7bc2a0a7",
   "metadata": {},
   "source": [
    "# POS\n",
    "It involves assigning parts of speech to each word in a sentence or text.\n",
    "## Tags\n",
    "- `NN` - Noun\n",
    "- `VB` - Verb\n",
    "- `JJ` - Adjective\n",
    "- `RB` - Adverb\n",
    "- `PRP` - Pronoun\n",
    "- `IN` - Preposition\n",
    "- `CC` - Conjunction\n",
    "- `DT` - Determiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feb452ab-35dc-4346-9021-94e06de3948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -> [('The', 'DT')]\n",
      "quick -> [('quick', 'NN')]\n",
      "brown -> [('brown', 'NN')]\n",
      "fox -> [('fox', 'NN')]\n",
      "jumps -> [('jumps', 'NNS')]\n",
      "over -> [('over', 'IN')]\n",
      "the -> [('the', 'DT')]\n",
      "lazy -> [('lazy', 'NN')]\n",
      "dog -> [('dog', 'NN')]\n",
      ". -> [('.', '.')]\n",
      "It -> [('It', 'PRP')]\n",
      "was -> [('was', 'VBD')]\n",
      "a -> [('a', 'DT')]\n",
      "sunny -> [('sunny', 'NN')]\n",
      "day -> [('day', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "for word in words:\n",
    "    print(f\"{word} -> {pos_tag([word])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63468f-8e4f-4707-847a-199f2717a182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
