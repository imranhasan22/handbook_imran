{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6300db64-bedc-492d-9b03-d664fadf9baa",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Linear Regression is a  statistical method used to model the relationship between a dependent variable (often denoted as \n",
    "ùëå\n",
    "Y) and one or more independent variables (denoted as \n",
    "ùëã\n",
    "X). The goal is to find the best-fitting line through the data points, which can predict the value of the dependent variable based on the independent variable(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce56087-d38d-41f9-82c9-3f703dc76e7d",
   "metadata": {},
   "source": [
    "__Types of Linear  Regression__\n",
    "- Simple Linear Regression: Involves a single independent variable.\n",
    "- Multiple Linear Regression: Involves multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8a7e1-d646-4ef1-a481-835e573293ab",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "The equation of a simple linear regression is:\n",
    "\n",
    "\\$ Y = \\beta_0 + \\beta_1 X + \\epsilon \\$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\$ Y \\$ = Dependent variable (what you're trying to predict)\n",
    "- \\$ X \\$ = Independent variable (predictor)\n",
    "- \\$ \\beta_0 \\$ = Intercept (the value of \\$ Y \\$ when \\$ X \\$ is 0)\n",
    "- \\$ \\beta_1 \\$ = Slope (how much \\$ Y \\$ changes for a unit change in \\$ X \\$)\n",
    "- \\$ \\epsilon \\$ = Error term (the difference between the actual and predicted values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dd541-f053-4813-8ad0-7769f8b01a16",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9584e91-e794-4c96-9cad-6da83c6cfb15",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1dd5c7-c6a2-4b64-b75b-1f1918e5a1e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Residuals\n",
    "Residuals represent the differences between the actual observed values of a dependent variable and the values predicted by a regression model.\n",
    "\n",
    "A residual for an individual observation is defined as:\n",
    "\n",
    "\\$\n",
    "\\text{Residual} = y_i - \\hat{y}_i\n",
    "\\$\n",
    "\n",
    "where:\n",
    "- \\$ y_i \\$ is the actual observed value of the dependent variable for the \\$ i \\$-th data point.\n",
    "- \\$ \\hat{y}_i \\$ is the predicted value for the same data point obtained from the regression model.\n",
    "\n",
    "\n",
    "It measures how far off the prediction is from the actual observation. A positive residual means the actual value is higher than predicted, while a negative residual indicates the actual value is lower than predicted.\n",
    "\n",
    "The residuals help assess how well the model fits the observed data. They are the errors made by the regression model when making predictions. The smaller the residuals, the better the model fits the data, as it means the predictions are close to the actual observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229586a7-886b-4e23-a25a-674aaad9a4da",
   "metadata": {},
   "source": [
    "## Least Squared Method\n",
    "The least squares method is used to find the best-fit line that minimizes the sum of the squared differences (residuals) between the observed values and the values predicted by the model.\n",
    "\n",
    "It aims to minimize Sum of Squared Residuals(__SSR__):\n",
    "\n",
    "\\$\n",
    "SSR =\\sum_{i=1}^{n}  \\left( Y_i - \\hat{Y}_i \\right)^2\n",
    "\\$\n",
    "\n",
    "This results in the best-fitting line.\n",
    "\n",
    "To minimize the total SSR, we need to solve for \\( \\beta_0 \\) and \\( \\beta_1 \\). Using calculus (derivatives), we can find the formulas for these values:\n",
    "\n",
    "The slope \\( \\beta_1 \\) is given by:\n",
    "\n",
    "\\$\n",
    "\\beta_1 = \\frac{n \\sum XY - \\sum X \\sum Y}{n \\sum X^2 - (\\sum X)^2}\n",
    "\\$\n",
    "\n",
    "The intercept \\( \\beta_0 \\) is given by:\n",
    "\n",
    "\\$\n",
    "\\beta_0 = \\frac{\\sum Y - \\beta_1 \\sum X}{n}\n",
    "\\$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\$ n \\$ is the number of data points,\n",
    "- \\$ \\sum X \\$ is the sum of all \\$ X \\$-values,\n",
    "- \\$ \\sum Y \\$ is the sum of all \\$ Y \\$-values,\n",
    "- \\$ \\sum XY \\$ is the sum of the product of corresponding \\$ X \\$ and \\$ Y \\$-values,\n",
    "- \\$ \\sum X^2 \\$ is the sum of the squares of the \\$ X \\$-values.\n",
    "\n",
    "\n",
    "### SSR\n",
    "SSR measure the overall performance of the model and to select the best model among different options based on their fit to the data. A smaller SSR indicates a better fit of the model to the data, as it suggests that the predicted values are closer to the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e26ae-0997-4f88-823c-61b3535156c3",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Linear Regression\n",
    "Several metrics are used to determine the quality of the model‚Äôs fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae24da6-90e7-462b-b3ab-1598c295c28a",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "MAE is the average of the absolute differences between the actual and predicted values. It measures the average magnitude of the errors without considering their direction.\n",
    "\n",
    "The Mean Absolute Error (MAE) is defined as:\n",
    "\n",
    "\\$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| Y_i - \\hat{Y}_i \\right|\n",
    "\\$\n",
    "\n",
    "Where:\n",
    "- \\$ Y_i \\$ is the actual value for the \\$ i \\$-th data point.\n",
    "- \\$ \\hat{Y}_i \\$ is the predicted value for the \\$ i \\$-th data point.\n",
    "- \\$ n \\$ is the total number of data points.\n",
    "\n",
    "__Range:__ 0 to ‚àû; lower values indicate a better fit.\n",
    "\n",
    "__Interpretation:__ MAE is less sensitive to outliers than MSE and RMSE because it does not square the errors. It provides a straightforward interpretation of the average error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c7ee8-a726-455f-b8cd-f38dbfc71a5b",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "MSE is the average of the squared differences between actual and predicted values. It quantifies the error in the model‚Äôs predictions.\n",
    "\n",
    "The Mean Squared Error (MSE) is defined as:\n",
    "\n",
    "\\$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} \\left( Y_i - \\hat{Y}_i \\right)^2\n",
    "\\$\n",
    "\n",
    "Where:\n",
    "- \\$ Y_i \\$: Actual value\n",
    "- \\$ \\hat{Y}_i \\$: Predicted value\n",
    "- \\$ n \\$: Number of observations\n",
    "\n",
    "__Range:__ 0 to ‚àû; lower values indicate a better fit.\n",
    "\n",
    "__Interpretation:__ Lower MSE indicates that the model's predictions are closer to the actual values.\n",
    "It is sensitive to outliers since it squares the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0e15a-c0e0-444a-a2cd-5d2111c3429f",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "RMSE is the square root of MSE, providing a measure of error in the same units as the dependent variable.\n",
    "\n",
    "The Root Mean Squared Error (RMSE) is defined as:\n",
    "\n",
    "\\$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left( Y_i - \\hat{Y}_i \\right)^2}\n",
    "\\$\n",
    "\n",
    "__Range:__ 0 to ‚àû; lower values indicate a better fit.\n",
    "\n",
    "__Interpretation:__ RMSE is easier to interpret than MSE because it is in the same units as the target variable.\n",
    "Lower RMSE indicates a more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374936c-29c0-40a4-87a5-02f7fcc2cad0",
   "metadata": {},
   "source": [
    "### R-squared (ùëÖ<sup>2</sup>)\n",
    "ùëÖ<sup>2</sup> measures the proportion of variance in the dependent variable that is explained by the independent variable(s). It indicates how well the independent variables predict the outcome.\n",
    "\n",
    "The \\$ R^2 \\$ (Coefficient of Determination) is defined as:\n",
    "\n",
    "\\$\n",
    "R^2 = 1 - \\frac{\\sum \\left( Y_i - \\bar{Y} \\right)^2}{\\sum \\left( Y_i - \\hat{Y}_i \\right)^2}\n",
    "\\$\n",
    "\n",
    "Where:\n",
    "- \\$ Y_i \\$: Actual value\n",
    "- \\$ \\bar{Y} \\$: Mean of actual values\n",
    "- \\$ \\hat{Y}_i \\$: Predicted value\n",
    "\n",
    "Range: 0‚â§ùëÖ<sup>2</sup>‚â§1\n",
    "\n",
    "__Interpretation:__\n",
    "\n",
    "- ùëÖ<sup>2</sup> = 0: The model does not explain any of the variance.\n",
    "- ùëÖ<sup>2</sup> = 1: The model perfectly explains the variance.\n",
    "- A higher ùëÖ<sup>2</sup> value indicates a better fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
